{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sASdreZ2AK4r"
   },
   "source": [
    "# <font color='maroon'>Assessment</font>\n",
    "Given the following dataset, answer the questions that follow. The necessary libraries have been imported.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-hfGUi4yAK4z"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from numpy import arange\n",
    "import scipy.stats as stats\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import random as rnd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4kZ-Kh9EAK5K"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Nn77q-wgAK5d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vivianopondoh/opt/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3058: DtypeWarning: Columns (27) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('athletes_.csv', sep=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "D1lo8v1zAK6C"
   },
   "source": [
    "### Question 1\n",
    "Study the data. What is the size of the dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11844168"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Return an int representing the number of elements in this object.\n",
    "data.size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ti3Di6QjAK6m"
   },
   "source": [
    "#### Question 1.1\n",
    "Generate summary statistics of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hg72ZotdAK6s"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>athlete_id</th>\n",
       "      <th>age</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>fran</th>\n",
       "      <th>helen</th>\n",
       "      <th>grace</th>\n",
       "      <th>filthy50</th>\n",
       "      <th>fgonebad</th>\n",
       "      <th>run400</th>\n",
       "      <th>run5k</th>\n",
       "      <th>candj</th>\n",
       "      <th>snatch</th>\n",
       "      <th>deadlift</th>\n",
       "      <th>backsq</th>\n",
       "      <th>pullups</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>423003.000000</td>\n",
       "      <td>331110.000000</td>\n",
       "      <td>1.598690e+05</td>\n",
       "      <td>229890.000000</td>\n",
       "      <td>5.542600e+04</td>\n",
       "      <td>3.027900e+04</td>\n",
       "      <td>4.074500e+04</td>\n",
       "      <td>1.935900e+04</td>\n",
       "      <td>2.973800e+04</td>\n",
       "      <td>2.224600e+04</td>\n",
       "      <td>3.609700e+04</td>\n",
       "      <td>1.044350e+05</td>\n",
       "      <td>9.728000e+04</td>\n",
       "      <td>1.153230e+05</td>\n",
       "      <td>1.105170e+05</td>\n",
       "      <td>5.060800e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>292748.166538</td>\n",
       "      <td>32.516750</td>\n",
       "      <td>1.206217e+02</td>\n",
       "      <td>170.896137</td>\n",
       "      <td>9.886691e+02</td>\n",
       "      <td>1.207950e+03</td>\n",
       "      <td>5.766025e+02</td>\n",
       "      <td>2.127863e+03</td>\n",
       "      <td>1.472252e+03</td>\n",
       "      <td>5.241279e+02</td>\n",
       "      <td>3.411464e+03</td>\n",
       "      <td>2.709107e+02</td>\n",
       "      <td>2.424957e+02</td>\n",
       "      <td>6.970503e+02</td>\n",
       "      <td>5.852109e+02</td>\n",
       "      <td>4.269613e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>184969.660327</td>\n",
       "      <td>7.730671</td>\n",
       "      <td>2.097995e+04</td>\n",
       "      <td>58.379799</td>\n",
       "      <td>7.200430e+04</td>\n",
       "      <td>6.824091e+04</td>\n",
       "      <td>4.891145e+04</td>\n",
       "      <td>6.055021e+04</td>\n",
       "      <td>9.762688e+04</td>\n",
       "      <td>5.628804e+04</td>\n",
       "      <td>1.251980e+05</td>\n",
       "      <td>2.596882e+04</td>\n",
       "      <td>2.708942e+04</td>\n",
       "      <td>5.523235e+04</td>\n",
       "      <td>5.052976e+04</td>\n",
       "      <td>9.546078e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>82.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>-6.000000e+01</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>-4.500000e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-5.000000e+02</td>\n",
       "      <td>-7.000000e+00</td>\n",
       "      <td>-6.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>135091.500000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>6.600000e+01</td>\n",
       "      <td>145.000000</td>\n",
       "      <td>2.150000e+02</td>\n",
       "      <td>5.250000e+02</td>\n",
       "      <td>1.490000e+02</td>\n",
       "      <td>1.308000e+03</td>\n",
       "      <td>2.400000e+02</td>\n",
       "      <td>6.200000e+01</td>\n",
       "      <td>1.242000e+03</td>\n",
       "      <td>1.400000e+02</td>\n",
       "      <td>1.050000e+02</td>\n",
       "      <td>2.550000e+02</td>\n",
       "      <td>2.050000e+02</td>\n",
       "      <td>1.500000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>275839.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>6.900000e+01</td>\n",
       "      <td>170.000000</td>\n",
       "      <td>2.900000e+02</td>\n",
       "      <td>5.950000e+02</td>\n",
       "      <td>1.930000e+02</td>\n",
       "      <td>1.550000e+03</td>\n",
       "      <td>2.940000e+02</td>\n",
       "      <td>7.100000e+01</td>\n",
       "      <td>1.380000e+03</td>\n",
       "      <td>1.950000e+02</td>\n",
       "      <td>1.450000e+02</td>\n",
       "      <td>3.450000e+02</td>\n",
       "      <td>2.750000e+02</td>\n",
       "      <td>2.700000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>473188.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>7.200000e+01</td>\n",
       "      <td>192.000000</td>\n",
       "      <td>3.920000e+02</td>\n",
       "      <td>6.940000e+02</td>\n",
       "      <td>2.620000e+02</td>\n",
       "      <td>1.809000e+03</td>\n",
       "      <td>3.360000e+02</td>\n",
       "      <td>8.400000e+01</td>\n",
       "      <td>1.560000e+03</td>\n",
       "      <td>2.350000e+02</td>\n",
       "      <td>1.850000e+02</td>\n",
       "      <td>4.150000e+02</td>\n",
       "      <td>3.350000e+02</td>\n",
       "      <td>3.900000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>633083.000000</td>\n",
       "      <td>125.000000</td>\n",
       "      <td>8.388607e+06</td>\n",
       "      <td>20175.000000</td>\n",
       "      <td>8.388607e+06</td>\n",
       "      <td>8.388607e+06</td>\n",
       "      <td>8.388607e+06</td>\n",
       "      <td>8.388607e+06</td>\n",
       "      <td>8.388607e+06</td>\n",
       "      <td>8.388607e+06</td>\n",
       "      <td>8.388607e+06</td>\n",
       "      <td>8.388607e+06</td>\n",
       "      <td>8.388607e+06</td>\n",
       "      <td>8.388607e+06</td>\n",
       "      <td>8.388607e+06</td>\n",
       "      <td>2.147484e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          athlete_id            age        height         weight  \\\n",
       "count  423003.000000  331110.000000  1.598690e+05  229890.000000   \n",
       "mean   292748.166538      32.516750  1.206217e+02     170.896137   \n",
       "std    184969.660327       7.730671  2.097995e+04      58.379799   \n",
       "min        82.000000      13.000000  0.000000e+00       1.000000   \n",
       "25%    135091.500000      27.000000  6.600000e+01     145.000000   \n",
       "50%    275839.000000      31.000000  6.900000e+01     170.000000   \n",
       "75%    473188.000000      37.000000  7.200000e+01     192.000000   \n",
       "max    633083.000000     125.000000  8.388607e+06   20175.000000   \n",
       "\n",
       "               fran         helen         grace      filthy50      fgonebad  \\\n",
       "count  5.542600e+04  3.027900e+04  4.074500e+04  1.935900e+04  2.973800e+04   \n",
       "mean   9.886691e+02  1.207950e+03  5.766025e+02  2.127863e+03  1.472252e+03   \n",
       "std    7.200430e+04  6.824091e+04  4.891145e+04  6.055021e+04  9.762688e+04   \n",
       "min    1.000000e+00  1.000000e+00 -6.000000e+01  1.000000e+00  0.000000e+00   \n",
       "25%    2.150000e+02  5.250000e+02  1.490000e+02  1.308000e+03  2.400000e+02   \n",
       "50%    2.900000e+02  5.950000e+02  1.930000e+02  1.550000e+03  2.940000e+02   \n",
       "75%    3.920000e+02  6.940000e+02  2.620000e+02  1.809000e+03  3.360000e+02   \n",
       "max    8.388607e+06  8.388607e+06  8.388607e+06  8.388607e+06  8.388607e+06   \n",
       "\n",
       "             run400         run5k         candj        snatch      deadlift  \\\n",
       "count  2.224600e+04  3.609700e+04  1.044350e+05  9.728000e+04  1.153230e+05   \n",
       "mean   5.241279e+02  3.411464e+03  2.709107e+02  2.424957e+02  6.970503e+02   \n",
       "std    5.628804e+04  1.251980e+05  2.596882e+04  2.708942e+04  5.523235e+04   \n",
       "min    1.000000e+00  1.000000e+00 -4.500000e+01  0.000000e+00 -5.000000e+02   \n",
       "25%    6.200000e+01  1.242000e+03  1.400000e+02  1.050000e+02  2.550000e+02   \n",
       "50%    7.100000e+01  1.380000e+03  1.950000e+02  1.450000e+02  3.450000e+02   \n",
       "75%    8.400000e+01  1.560000e+03  2.350000e+02  1.850000e+02  4.150000e+02   \n",
       "max    8.388607e+06  8.388607e+06  8.388607e+06  8.388607e+06  8.388607e+06   \n",
       "\n",
       "             backsq       pullups  \n",
       "count  1.105170e+05  5.060800e+04  \n",
       "mean   5.852109e+02  4.269613e+04  \n",
       "std    5.052976e+04  9.546078e+06  \n",
       "min   -7.000000e+00 -6.000000e+00  \n",
       "25%    2.050000e+02  1.500000e+01  \n",
       "50%    2.750000e+02  2.700000e+01  \n",
       "75%    3.350000e+02  3.900000e+01  \n",
       "max    8.388607e+06  2.147484e+09  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Descriptive statistics include those that summarize the central tendency, dispersion and shape of a datasetâ€™s distribution, excluding NaN values.\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cNlUUTDOAK7F"
   },
   "source": [
    "#### Question 1.2\n",
    "Are the any missing values?  A simple strategy would be to remove rows with missing values. This can however reduce the size of the dataset. Another technique is to imput missing values with a sensible value like the mean.\n",
    "\n",
    "For more on how to deal with missing values, see this blog entry: [How to Handle Missing Data with Python](https://machinelearningmastery.com/handle-missing-data-python/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6uLGppKNAK7N"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "athlete_id       0\n",
      "age              0\n",
      "height          21\n",
      "weight           0\n",
      "fran             0\n",
      "helen            0\n",
      "grace            0\n",
      "filthy50         0\n",
      "fgonebad      3033\n",
      "run400           0\n",
      "run5k            0\n",
      "candj         3383\n",
      "snatch        3312\n",
      "deadlift      3685\n",
      "backsq        3507\n",
      "pullups       3382\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print((data[['athlete_id','age','height','weight','fran','helen','grace','filthy50','fgonebad','run400','run5k','candj','snatch','deadlift','backsq','pullups']] == 0).sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mrGe0lq8AK7g"
   },
   "source": [
    "### Question 2\n",
    "\n",
    "Study the `height` column. What distribution does the data follow? \n",
    "Hint: Use a histogram or density plot to visualise the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BYKF8yDcAK7n"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9CWceB2gAK70"
   },
   "source": [
    "### Question 3\n",
    "What is the average height?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GSzqNCn4AK77"
   },
   "outputs": [],
   "source": [
    "data.height.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "519vK1kjAK8O"
   },
   "source": [
    "### Question 4\n",
    "\n",
    "Use simple random sampling to sample from the dataset. Choose a sample of 20000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "V57d_OazAK8U"
   },
   "outputs": [],
   "source": [
    "data.sample(n=2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vNY59IIfAK8g"
   },
   "source": [
    "### Question 4\n",
    "\n",
    "Use stratified sampling to sample from the dataset. Choose a sample of 20000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jC35zNLWAK8k"
   },
   "outputs": [],
   "source": [
    "# your answers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jN1d7dnLAK8w"
   },
   "source": [
    "### Question 5\n",
    "Compare simple random sampling and stratified random sampling. Compare the means generated by the two sampling techniques and discuss your observations below your code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4JHPs2AKAK80"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GStf2Ah0AK9E"
   },
   "source": [
    "### Question 6 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Lw20bGLVAK9I"
   },
   "source": [
    "In  this question we are going to implement cluster sampling. Data is divided into clusters, if it isn't already divided into clusters, and then we use simple random sampling to select a number of clusters from the sample. From the group of selected clusters, we again use simple random sampling to select random data points. These now form our sample.  \n",
    "\n",
    "Let's implement this procedure using some randomly generated data that we are going to group into clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "w9SowrZGAK9M"
   },
   "outputs": [],
   "source": [
    "n_clusters = 10\n",
    "data = stats.norm.rvs(loc=0,        # mean 0\n",
    "                      scale=1,      # variance 1\n",
    "                      size=100000,  # number of points\n",
    "                      random_state=None)\n",
    "\n",
    "data = pd.DataFrame({'var1': data})  # turn list into dataframe with heading var1\n",
    "\n",
    "cluster = [rnd.randint(0,9) for c in range(100000)] # generate cluster numbers for grouping\n",
    "\n",
    "n_col = pd.Series(cluster) # turn list into Series object\n",
    "data['cluster'] = n_col.values\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WyQAkSpLAK9d"
   },
   "source": [
    "Now that we've generated random data and placed the data into clusters, generate a sample from the *athletes* data using cluster sampling technique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yJDAt_c2AK9j"
   },
   "outputs": [],
   "source": [
    "# your answers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UmKTSwrTAK9_"
   },
   "source": [
    "<!-- Distribution fitting with scipy exercise given a dataset. Good references about El Nino dataset. I should find a climate dataset.\n",
    "\n",
    "https://stackoverflow.com/questions/6615489/fitting-distributions-goodness-of-fit-p-value-is-it-possible-to-do-this-with/16651524#16651524\n",
    "\n",
    "https://stackoverflow.com/questions/6620471/fitting-empirical-distribution-to-theoretical-ones-with-scipy-python -->"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "dav_15_HLT_assignment.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
