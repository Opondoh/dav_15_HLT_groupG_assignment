{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sASdreZ2AK4r"
   },
   "source": [
    "# <font color='maroon'>Assessment</font>\n",
    "Given the following dataset, answer the questions that follow. The necessary libraries have been imported.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-hfGUi4yAK4z"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from numpy import arange\n",
    "import scipy.stats as stats\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import random as rnd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4kZ-Kh9EAK5K"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip freeze > requirement.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Nn77q-wgAK5d"
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('athletes_.csv', sep=',', low_memory=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "D1lo8v1zAK6C"
   },
   "source": [
    "### Question 1\n",
    "Study the data. What is the size of the dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11844168"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Return an int representing the number of elements in this object.\n",
    "data.size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ti3Di6QjAK6m"
   },
   "source": [
    "#### Question 1.1\n",
    "Generate summary statistics of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>athlete_id</th>\n",
       "      <th>age</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>fran</th>\n",
       "      <th>helen</th>\n",
       "      <th>grace</th>\n",
       "      <th>filthy50</th>\n",
       "      <th>fgonebad</th>\n",
       "      <th>run400</th>\n",
       "      <th>run5k</th>\n",
       "      <th>candj</th>\n",
       "      <th>snatch</th>\n",
       "      <th>deadlift</th>\n",
       "      <th>backsq</th>\n",
       "      <th>pullups</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>423003.000000</td>\n",
       "      <td>331110.000000</td>\n",
       "      <td>1.598690e+05</td>\n",
       "      <td>229890.000000</td>\n",
       "      <td>5.542600e+04</td>\n",
       "      <td>3.027900e+04</td>\n",
       "      <td>4.074500e+04</td>\n",
       "      <td>1.935900e+04</td>\n",
       "      <td>2.973800e+04</td>\n",
       "      <td>2.224600e+04</td>\n",
       "      <td>3.609700e+04</td>\n",
       "      <td>1.044350e+05</td>\n",
       "      <td>9.728000e+04</td>\n",
       "      <td>1.153230e+05</td>\n",
       "      <td>1.105170e+05</td>\n",
       "      <td>5.060800e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>292748.166538</td>\n",
       "      <td>32.516750</td>\n",
       "      <td>1.206217e+02</td>\n",
       "      <td>170.896137</td>\n",
       "      <td>9.886691e+02</td>\n",
       "      <td>1.207950e+03</td>\n",
       "      <td>5.766025e+02</td>\n",
       "      <td>2.127863e+03</td>\n",
       "      <td>1.472252e+03</td>\n",
       "      <td>5.241279e+02</td>\n",
       "      <td>3.411464e+03</td>\n",
       "      <td>2.709107e+02</td>\n",
       "      <td>2.424957e+02</td>\n",
       "      <td>6.970503e+02</td>\n",
       "      <td>5.852109e+02</td>\n",
       "      <td>4.269613e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>184969.660327</td>\n",
       "      <td>7.730671</td>\n",
       "      <td>2.097995e+04</td>\n",
       "      <td>58.379799</td>\n",
       "      <td>7.200430e+04</td>\n",
       "      <td>6.824091e+04</td>\n",
       "      <td>4.891145e+04</td>\n",
       "      <td>6.055021e+04</td>\n",
       "      <td>9.762688e+04</td>\n",
       "      <td>5.628804e+04</td>\n",
       "      <td>1.251980e+05</td>\n",
       "      <td>2.596882e+04</td>\n",
       "      <td>2.708942e+04</td>\n",
       "      <td>5.523235e+04</td>\n",
       "      <td>5.052976e+04</td>\n",
       "      <td>9.546078e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>82.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>-6.000000e+01</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>-4.500000e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-5.000000e+02</td>\n",
       "      <td>-7.000000e+00</td>\n",
       "      <td>-6.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>135091.500000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>6.600000e+01</td>\n",
       "      <td>145.000000</td>\n",
       "      <td>2.150000e+02</td>\n",
       "      <td>5.250000e+02</td>\n",
       "      <td>1.490000e+02</td>\n",
       "      <td>1.308000e+03</td>\n",
       "      <td>2.400000e+02</td>\n",
       "      <td>6.200000e+01</td>\n",
       "      <td>1.242000e+03</td>\n",
       "      <td>1.400000e+02</td>\n",
       "      <td>1.050000e+02</td>\n",
       "      <td>2.550000e+02</td>\n",
       "      <td>2.050000e+02</td>\n",
       "      <td>1.500000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>275839.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>6.900000e+01</td>\n",
       "      <td>170.000000</td>\n",
       "      <td>2.900000e+02</td>\n",
       "      <td>5.950000e+02</td>\n",
       "      <td>1.930000e+02</td>\n",
       "      <td>1.550000e+03</td>\n",
       "      <td>2.940000e+02</td>\n",
       "      <td>7.100000e+01</td>\n",
       "      <td>1.380000e+03</td>\n",
       "      <td>1.950000e+02</td>\n",
       "      <td>1.450000e+02</td>\n",
       "      <td>3.450000e+02</td>\n",
       "      <td>2.750000e+02</td>\n",
       "      <td>2.700000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>473188.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>7.200000e+01</td>\n",
       "      <td>192.000000</td>\n",
       "      <td>3.920000e+02</td>\n",
       "      <td>6.940000e+02</td>\n",
       "      <td>2.620000e+02</td>\n",
       "      <td>1.809000e+03</td>\n",
       "      <td>3.360000e+02</td>\n",
       "      <td>8.400000e+01</td>\n",
       "      <td>1.560000e+03</td>\n",
       "      <td>2.350000e+02</td>\n",
       "      <td>1.850000e+02</td>\n",
       "      <td>4.150000e+02</td>\n",
       "      <td>3.350000e+02</td>\n",
       "      <td>3.900000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>633083.000000</td>\n",
       "      <td>125.000000</td>\n",
       "      <td>8.388607e+06</td>\n",
       "      <td>20175.000000</td>\n",
       "      <td>8.388607e+06</td>\n",
       "      <td>8.388607e+06</td>\n",
       "      <td>8.388607e+06</td>\n",
       "      <td>8.388607e+06</td>\n",
       "      <td>8.388607e+06</td>\n",
       "      <td>8.388607e+06</td>\n",
       "      <td>8.388607e+06</td>\n",
       "      <td>8.388607e+06</td>\n",
       "      <td>8.388607e+06</td>\n",
       "      <td>8.388607e+06</td>\n",
       "      <td>8.388607e+06</td>\n",
       "      <td>2.147484e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          athlete_id            age        height         weight  \\\n",
       "count  423003.000000  331110.000000  1.598690e+05  229890.000000   \n",
       "mean   292748.166538      32.516750  1.206217e+02     170.896137   \n",
       "std    184969.660327       7.730671  2.097995e+04      58.379799   \n",
       "min        82.000000      13.000000  0.000000e+00       1.000000   \n",
       "25%    135091.500000      27.000000  6.600000e+01     145.000000   \n",
       "50%    275839.000000      31.000000  6.900000e+01     170.000000   \n",
       "75%    473188.000000      37.000000  7.200000e+01     192.000000   \n",
       "max    633083.000000     125.000000  8.388607e+06   20175.000000   \n",
       "\n",
       "               fran         helen         grace      filthy50      fgonebad  \\\n",
       "count  5.542600e+04  3.027900e+04  4.074500e+04  1.935900e+04  2.973800e+04   \n",
       "mean   9.886691e+02  1.207950e+03  5.766025e+02  2.127863e+03  1.472252e+03   \n",
       "std    7.200430e+04  6.824091e+04  4.891145e+04  6.055021e+04  9.762688e+04   \n",
       "min    1.000000e+00  1.000000e+00 -6.000000e+01  1.000000e+00  0.000000e+00   \n",
       "25%    2.150000e+02  5.250000e+02  1.490000e+02  1.308000e+03  2.400000e+02   \n",
       "50%    2.900000e+02  5.950000e+02  1.930000e+02  1.550000e+03  2.940000e+02   \n",
       "75%    3.920000e+02  6.940000e+02  2.620000e+02  1.809000e+03  3.360000e+02   \n",
       "max    8.388607e+06  8.388607e+06  8.388607e+06  8.388607e+06  8.388607e+06   \n",
       "\n",
       "             run400         run5k         candj        snatch      deadlift  \\\n",
       "count  2.224600e+04  3.609700e+04  1.044350e+05  9.728000e+04  1.153230e+05   \n",
       "mean   5.241279e+02  3.411464e+03  2.709107e+02  2.424957e+02  6.970503e+02   \n",
       "std    5.628804e+04  1.251980e+05  2.596882e+04  2.708942e+04  5.523235e+04   \n",
       "min    1.000000e+00  1.000000e+00 -4.500000e+01  0.000000e+00 -5.000000e+02   \n",
       "25%    6.200000e+01  1.242000e+03  1.400000e+02  1.050000e+02  2.550000e+02   \n",
       "50%    7.100000e+01  1.380000e+03  1.950000e+02  1.450000e+02  3.450000e+02   \n",
       "75%    8.400000e+01  1.560000e+03  2.350000e+02  1.850000e+02  4.150000e+02   \n",
       "max    8.388607e+06  8.388607e+06  8.388607e+06  8.388607e+06  8.388607e+06   \n",
       "\n",
       "             backsq       pullups  \n",
       "count  1.105170e+05  5.060800e+04  \n",
       "mean   5.852109e+02  4.269613e+04  \n",
       "std    5.052976e+04  9.546078e+06  \n",
       "min   -7.000000e+00 -6.000000e+00  \n",
       "25%    2.050000e+02  1.500000e+01  \n",
       "50%    2.750000e+02  2.700000e+01  \n",
       "75%    3.350000e+02  3.900000e+01  \n",
       "max    8.388607e+06  2.147484e+09  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Generate descriptive statistics.\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cNlUUTDOAK7F"
   },
   "source": [
    "#### Question 1.2\n",
    "Are the any missing values?  A simple strategy would be to remove rows with missing values. This can however reduce the size of the dataset. Another technique is to imput missing values with a sensible value like the mean.\n",
    "\n",
    "For more on how to deal with missing values, see this blog entry: [How to Handle Missing Data with Python](https://machinelearningmastery.com/handle-missing-data-python/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "athlete_id         3\n",
      "name           91896\n",
      "region        171744\n",
      "team          267846\n",
      "affiliate     181090\n",
      "gender         91896\n",
      "age            91896\n",
      "height        263158\n",
      "weight        193116\n",
      "fran          367580\n",
      "helen         392727\n",
      "grace         382261\n",
      "filthy50      403647\n",
      "fgonebad      396301\n",
      "run400        400760\n",
      "run5k         386909\n",
      "candj         321954\n",
      "snatch        329038\n",
      "deadlift      311368\n",
      "backsq        315996\n",
      "pullups       375780\n",
      "dtype: int64\n",
      "(423006, 21)\n"
     ]
    }
   ],
   "source": [
    "#Mark 0 values to NaN and check sum missing values\n",
    "dataMissing = data[['athlete_id','name', 'region', 'team', 'affiliate', 'gender','age','height','weight','fran','helen','grace','filthy50','fgonebad','run400','run5k','candj','snatch','deadlift','backsq','pullups']] = data[['athlete_id','name', 'region', 'team', 'affiliate', 'gender','age','height','weight','fran','helen','grace','filthy50','fgonebad','run400','run5k','candj','snatch','deadlift','backsq','pullups']].replace(0, np.NaN)\n",
    "\n",
    "#Count the number of NaN values in each column\n",
    "print(dataMissing.isnull().sum())\n",
    "\n",
    "#Check number of rows and colums\n",
    "print(dataMissing.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1488, 21)\n"
     ]
    }
   ],
   "source": [
    "#Drop rows with missing values\n",
    "dataDrop = dataMissing.dropna(inplace=True)\n",
    "\n",
    "#Summarize the number of rows and columns in the dataset\n",
    "print(dataMissing.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mrGe0lq8AK7g"
   },
   "source": [
    "### Question 2\n",
    "\n",
    "Study the `height` column. What distribution does the data follow? \n",
    "Hint: Use a histogram or density plot to visualise the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    1.598480e+05\n",
       "mean     1.206375e+02\n",
       "std      2.098133e+04\n",
       "min      1.000000e+00\n",
       "25%      6.600000e+01\n",
       "50%      6.900000e+01\n",
       "75%      7.200000e+01\n",
       "max      8.388607e+06\n",
       "Name: height, dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check summarized values of 'height'\n",
    "data['height'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'height'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-e2c025946733>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#Check for new summarized values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mdataHeight\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'height'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdescribe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1066\u001b[0m         \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1067\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1068\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1069\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1070\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_value\u001b[0;34m(self, series, key)\u001b[0m\n\u001b[1;32m   4728\u001b[0m         \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_scalar_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkind\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"getitem\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4729\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4730\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtz\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseries\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"tz\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4731\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4732\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mholds_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_boolean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_value\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_value\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.index.Int64Engine._check_type\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'height'"
     ]
    }
   ],
   "source": [
    "#Mark 8388607 values as missing or NaN, value appears to be misplaced showing up on text columns.\n",
    "#Throws off the height summarized values\n",
    "dataHeight = data['height'] = data['height'].replace(8388607, np.NaN)\n",
    "                                   \n",
    "#Check for new summarized values\n",
    "dataHeight['height'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9CWceB2gAK70"
   },
   "source": [
    "### Question 3\n",
    "What is the average height?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GSzqNCn4AK77"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "519vK1kjAK8O"
   },
   "source": [
    "### Question 4\n",
    "\n",
    "Use simple random sampling to sample from the dataset. Choose a sample of 20000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vNY59IIfAK8g"
   },
   "source": [
    "### Question 4\n",
    "\n",
    "Use stratified sampling to sample from the dataset. Choose a sample of 20000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jC35zNLWAK8k"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jN1d7dnLAK8w"
   },
   "source": [
    "### Question 5\n",
    "Compare simple random sampling and stratified random sampling. Compare the means generated by the two sampling techniques and discuss your observations below your code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "athlete_id "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GStf2Ah0AK9E"
   },
   "source": [
    "### Question 6 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Lw20bGLVAK9I"
   },
   "source": [
    "In  this question we are going to implement cluster sampling. Data is divided into clusters, if it isn't already divided into clusters, and then we use simple random sampling to select a number of clusters from the sample. From the group of selected clusters, we again use simple random sampling to select random data points. These now form our sample.  \n",
    "\n",
    "Let's implement this procedure using some randomly generated data that we are going to group into clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "w9SowrZGAK9M"
   },
   "outputs": [],
   "source": [
    "#n_clusters = 10\n",
    "#data = stats.norm.rvs(loc=0,        # mean 0\n",
    "                      #scale=1,      # variance 1\n",
    "                      #size=100000,  # number of points\n",
    "                      #random_state=None)\n",
    "\n",
    "#data = pd.DataFrame({'var1': data})  # turn list into dataframe with heading var1\n",
    "\n",
    "#cluster = [rnd.randint(0,9) for c in range(100000)] # generate cluster numbers for grouping\n",
    "\n",
    "#n_col = pd.Series(cluster) # turn list into Series object\n",
    "#data['cluster'] = n_col.values\n",
    "#data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WyQAkSpLAK9d"
   },
   "source": [
    "Now that we've generated random data and placed the data into clusters, generate a sample from the *athletes* data using cluster sampling technique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yJDAt_c2AK9j"
   },
   "outputs": [],
   "source": [
    "# your answers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UmKTSwrTAK9_"
   },
   "source": [
    "<!-- Distribution fitting with scipy exercise given a dataset. Good references about El Nino dataset. I should find a climate dataset.\n",
    "\n",
    "https://stackoverflow.com/questions/6615489/fitting-distributions-goodness-of-fit-p-value-is-it-possible-to-do-this-with/16651524#16651524\n",
    "\n",
    "https://stackoverflow.com/questions/6620471/fitting-empirical-distribution-to-theoretical-ones-with-scipy-python -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "dav_15_HLT_assignment.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
